<!DOCTYPE html>
<html lang="en-US">
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Curriculum Vitae | Yuekai Sun</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Curriculum Vitae" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Yuekai is an assistant professor in the statistics department at the University of Michigan. His research leverages statistical science to make AI safer and more reliable in the real world." />
<meta property="og:description" content="Yuekai is an assistant professor in the statistics department at the University of Michigan. His research leverages statistical science to make AI safer and more reliable in the real world." />
<link rel="canonical" href="https://yuekai.github.io/cv/" />
<meta property="og:url" content="https://yuekai.github.io/cv/" />
<meta property="og:site_name" content="Yuekai Sun" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Curriculum Vitae" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Yuekai is an assistant professor in the statistics department at the University of Michigan. His research leverages statistical science to make AI safer and more reliable in the real world.","headline":"Curriculum Vitae","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://yuekai.github.io/assets/img/yuekai.jpg"}},"url":"https://yuekai.github.io/cv/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="https://yuekai.github.io/assets/css/style.css">
  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
  <![endif]-->
  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
  <script src="https://kit.fontawesome.com/ef661a1083.js" crossorigin="anonymous"></script>
  
  <link rel="shortcut icon" type="image/x-icon" href="https://yuekai.github.io/assets/favicon/favicon.ico">
  <link rel="apple-touch-icon-precomposed" href="https://yuekai.github.io/assets/favicon/apple-touch-icon.png">
</head>
  <body>
    <div id="container">

      <header>
  <h1><a href="https://yuekai.github.io/">Yuekai Sun</a></h1>

  
  <figure id="profile-pic" style="max-width:168px;"><img src="/assets/img/yuekai.jpg" alt="profile pic"></figure>
  
  
  <nav>
    <ul><li>
        <a href="https://yuekai.github.io/research/">Research</a>
      </li><li>
        <a href="https://yuekai.github.io/papers/">Papers</a>
      </li><li>
        <a href="https://yuekai.github.io/teaching/">Teaching</a>
      </li></ul>
  </nav>
</header>

      <section>

      <h1 id="curriculum-vitae">Curriculum Vitae</h1>

<h2 id="education">Education</h2>

<dl>
  <dt>2010–2015</dt>
  <dd><strong>PhD Computational &amp; Mathematical Engineering</strong>, Stanford University <br />
Thesis: <a href="https://searchworks.stanford.edu/view/11061393">Regularization in high-dimensional statistics</a></dd>
  <dt>2006–2010</dt>
  <dd><strong>BA Computational and Applied Mathematics (CAAM)</strong>, Rice University</dd>
</dl>

<h2 id="academic-appointments">Academic appointments</h2>

<dl>
  <dt>2025–</dt>
  <dd><strong>Program Director</strong>, Data Science Master’s Program, University of Michigan</dd>
  <dt>2016–</dt>
  <dd><strong>Assistant → Associate Professor of Statistics</strong>, University of Michigan<br />
Promoted to Associate Professor (with tenure) in 2023</dd>
  <dt>2015–2016</dt>
  <dd><strong>Neyman Visiting Assistant Professor</strong>, UC Berkeley</dd>
</dl>

<h2 id="industry-experience">Industry experience</h2>

<dl>
  <dt>2013</dt>
  <dd><strong>Research Intern</strong>, Technicolor Research &amp; Innovation</dd>
  <dt>2008–2009</dt>
  <dd><strong>Teaching Fellow</strong>, <a href="https://breakthroughhouston.org/">Breakthrough Houston</a></dd>
</dl>

<h2 id="honors-and-awards">Honors and awards</h2>

<dl>
  <dt>2017</dt>
  <dd><a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1562089"><strong>ASQ Jack Youden Prize</strong></a></dd>
  <dt>2015</dt>
  <dd><strong>Stanford ICME Super Hero Award</strong></dd>
  <dt>2010</dt>
  <dd><strong>Stanford School of Engineering Graduate Fellowship</strong></dd>
  <dt>2009</dt>
  <dd><a href="https://cmor.rice.edu/academics/undergraduate-programs/undergraduate-awards"><strong>Rice CAAM Chevron Prize</strong></a></dd>
  <dt>2009</dt>
  <dd><strong>Rice Engineering Louis J Walsh Scholarship</strong></dd>
  <dt>2008</dt>
  <dd><strong>Rice Engineering WM Moody Jr Scholarship</strong></dd>
</dl>

<h2 id="grants">Grants</h2>

<dl>
  <dt>Sep 2024–Aug 2027</dt>
  <dd><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2414918"><strong>CIF: Small: Learning in Strategic Environments with Applications in Algorithmic Fairness</strong></a><br />
NSF CCF 2414918. Award amount: $544k.</dd>
  <dt>Jul 2024–Jun 2025</dt>
  <dd><strong>OpenAI Superalignment Fast Grant: A Mathematical Theory of Weak-to-strong Generalization</strong><br />
Award amount: $102k.</dd>
  <dt>Aug 2022–<br />Jul 2024</dt>
  <dd><strong>Confident Learning with Uncertainty Estimates</strong><br />
DARPA HR00112290111. PI: Elizabeth Hou. My/Total award amount: $184k/$1M.</dd>
  <dt>Aug 2021–<br />Jul 2024</dt>
  <dd><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2113373"><strong>A Transfer Learning Approach to Algorithmic Fairness</strong></a><br />
NSF DMS 2113373. Award amount: $150k.</dd>
  <dt>Sep 2021–<br />Aug 2024</dt>
  <dd><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2027737"><strong>ATD: Algorithmic Threat Detection and Mitigation with Robust Machine Learning</strong></a><br />
NSF DMS 2027737. Award amount: $330k.</dd>
  <dt>Sep 2019–<br />Aug 2022</dt>
  <dd><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1916271"><strong>Integrative Analysis of Heterogeneous Datasets with High-Dimensional and Non-Standard Models</strong></a><br />
NSF DMS 1916271. Award amount: $180k.</dd>
  <dt>Aug 2018–<br />Jul 2021</dt>
  <dd><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1830247"><strong>ATD: Collaborative Research: Statistically Principled Real-Time Detection of Anomalies in Temporal Network Data</strong></a><br />
NSF DMS 1830247. My/Total award amount: $75k/$200k.</dd>
</dl>

<h2 id="professional-activities">Professional activities</h2>

<dl>
  <dt>2023–</dt>
  <dd><strong>Co-editor</strong> (with Samory Kpotufe and Richard Samworth), Statistical Science Special Issue on “Learning Across Distributions”</dd>
  <dt>2023</dt>
  <dd><strong>Organizing committee member</strong>, 2023 ICSA Applied Statistics Symposium</dd>
  <dt>2022–</dt>
  <dd><strong>Associate Editor</strong>, Statistical Science</dd>
</dl>

<h2 id="teaching">Teaching</h2>

<h3 id="university-of-michigan">University of Michigan</h3>

<dl>
  <dt>Win 2020-2023</dt>
  <dd><a href="http://www-personal.umich.edu/~yuekai/stats606/"><strong>STATS 606: Computation and Optimization Methods in Statistics</strong></a><br />
This course combines STATS 608a and STATS 607b.</dd>
  <dt>Fall 2018, 2022, 2024</dt>
  <dd><a href="http://www-personal.umich.edu/~yuekai/stats415/"><strong>STATS 415: Data Mining and Machine Learning</strong></a><br /></dd>
  <dt>Win 2022</dt>
  <dd><strong>STATS 701: Topics in algorithmic fairness</strong></dd>
  <dt>Fall 2021, ‘17, ‘16, Win ‘17</dt>
  <dd><a href="http://www-personal.umich.edu/~yuekai/stats413/"><strong>STATS 413: Applied Regression Analysis</strong></a></dd>
  <dt>Fall 2020</dt>
  <dd><strong>STATS 451: Bayesian Data Analysis</strong></dd>
  <dt>Fall 2018, ‘17</dt>
  <dd><strong>STATS 608a: Optimization Methods in Statistics</strong></dd>
  <dt>Sum 2018</dt>
  <dd><strong>VE 488: Data Mining and Machine Learning</strong><br />
This course was offered at the UM-SJTU Joint Institute; it is identical to STATS 415.</dd>
  <dt>Win 2019, ‘18</dt>
  <dd><strong>STATS 607b: Numerical Methods in Statistics</strong></dd>
</dl>

<h3 id="uc-berkeley">UC Berkeley</h3>

<dl>
  <dt>Spr 2016</dt>
  <dd><strong>STAT 153: Introduction to Time Series</strong></dd>
  <dt>Fall 2015</dt>
  <dd><strong>STAT 201B: Introduction to Statistics at an Advanced Level</strong></dd>
</dl>

<h2 id="phd-students">PhD students</h2>

<dl>
  <dt>2021–</dt>
  <dd><strong>Seamus Somerstep</strong> (co-advised with <a href="https://websites.umich.edu/~yritov/jr.html">Ya’acov Ritov</a>)<br /></dd>
  <dt>2021–</dt>
  <dd><a href="https://dbracale.github.io"><strong>Daniele Bracale</strong></a> (co-advised with Mouli Banerjee)<br /></dd>
  <dt>2021–</dt>
  <dd><a href="https://felipemaiapolo.github.io"><strong>Felipe Maia Polo</strong></a> (co-advised with Mouli Banerjee)<br /></dd>
  <dt>2020–</dt>
  <dd><strong>Pramit Das</strong> (co-advised with Mouli Banerjee)<br /></dd>
  <dt>2018–2024</dt>
  <dd><a href="http://www-personal.umich.edu/~sxue/"><strong>Songkai Xue</strong></a><br />
Thesis: <a href="https://dx.doi.org/10.7302/24078">Advances in Machine Learning Safety</a><br />
Songkai is a Research Scientist at Huawei.</dd>
  <dt>2018–2024</dt>
  <dd><a href="https://sites.google.com/umich.edu/smaity/home"><strong>Subha Maity</strong></a> (co-advised with <a href="https://dept.stat.lsa.umich.edu/~moulib/main-info.html">Mouli Banerjee</a>)<br />
Thesis: <a href="https://dx.doi.org/10.7302/24065">An Exploration of the Statistical Challenges and Fairness Implications of Transfer Learning</a><br />
Subha is an Assistant Professor in the Department of Statistics and Actuarial Science at the University of Waterloo.</dd>
  <dt>2016–2022</dt>
  <dd><strong>Laura Niss</strong> (co-advised with <a href="https://ambujtewari.github.io">Ambuj Tewari</a>) <br />
Thesis: <a href="https://dx.doi.org/10.7302/6031">Topics in Sequential Decision Making and Algorithmic Fairness</a><br />
Laura is a member of the Technical Staff at MIT Lincoln Laboratory.</dd>
  <dt>2014–2020</dt>
  <dd><strong>Roger Fan</strong> (co-advised with <a href="https://sites.google.com/view/shuhengz">Shuheng Zhou</a>) <br />
Thesis: <a href="https://hdl.handle.net/2027.42/163035">Covariance Estimation with Missing and Dependent Data</a><br />
Roger is a Research Scientist at Amazon.</dd>
  <dt>2014–2019</dt>
  <dd><strong>Ruofei Zhao</strong><br />
Thesis: <a href="https://deepblue.lib.umich.edu/handle/2027.42/151538">Convergence and Consistency Results in Spectral Clustering and Gaussian Mixture Models</a><br />
Ruofei is a Quantitative Researcher at Sunrise Futures LLC.</dd>
</dl>

<h2 id="papers">Papers</h2>

<p>See <a href="https://scholar.google.com/citations?user=6T1XtW8AAAAJ">Google Scholar</a> for citation metrics.</p>

<h3 id="preprints">Preprints</h3>

<p><a href="https://arxiv.org/abs/2503.16737"><strong>Optimal Nonlinear Online Learning under Sequential Price Competition via s-Concavity</strong></a><br />
D Bracale, M Banerjee, C Shi, Y Sun.</p>

<p><a href="https://arxiv.org/abs/2502.07111"><strong>Likelihood-Free Estimation for Spatiotemporal Hawkes processes with missing data and application to predictive policing</strong></a><br />
P Das, M Banerjee, Y Sun.</p>

<p><a href="https://arxiv.org/abs/2502.05776"><strong>Dynamic Pricing in the Linear Valuation Model using Shape Constraints</strong></a><br />
D Bracale, M Banerjee, Y Sun, K Stoll, S Turki.</p>

<p><a href="https://arxiv.org/abs/2412.06540"><strong>Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families</strong></a><br />
F Maia Polo, S Somerstep, L Choshen, Y Sun, M Yurochkin.</p>

<p><a href="https://arxiv.org/abs/2412.06540"><strong>Sloth: scaling laws for LLM skills to predict multi-benchmark performance across families</strong></a><br />
F Maia Polo, S Somerstep, L Choshen, Y Sun, M Yurochkin.</p>

<p><a href="https://arxiv.org/abs/2411.08998"><strong>Microfoundation Inference for Strategic Prediction</strong></a><br />
D Bracale, S Maity, F Maia Polo, S Somerstep, M Banerjee, Y Sun. to appear in AISTATS 2025.</p>

<p><a href="https://openreview.net/forum?id=SulRfnEVK4"><strong>LiveXiv — A Multi-Modal Live Benchmark Based on Arxiv Papers Content</strong></a><br />
N Shabtay, F Maia Polo, S Doveh, W Lin, J Mirza, L Chosen, M Yurochkin, Y Sun, A Arbelle, L Karlinsky, R Giryes. to appear in ICLR 2025.</p>

<p><a href="https://openreview.net/forum?id=PeLLMw3wLX"><strong>A transfer learning framework for weak-to-strong generalization</strong></a><br />
S Somerstep, F Maia Polo, M Banerjee, Y Ritov, M Yurochkin, Y Sun. to appear in ICLR 2025.</p>

<p><a href="https://arxiv.org/abs/2405.15172"><strong>Learning the Distribution Map in Reverse Causal Performative Prediction</strong></a><br />
D Bracale, S Maity, S Somerstep, M Banerjee, Y Sun. to appear in AISTATS 2025.</p>

<h3 id="journal-papers">Journal papers</h3>

<p><a href="https://doi.org/10.1093/biomet/asad029"><strong>A linear adjustment based approach to posterior drift in transfer learning</strong></a><br />
S Maity, D Dutta, J Terhorst, Y Sun, M Banerjee. <em>Biometrika</em> (2024).</p>

<p><a href="https://jmlr.org/papers/v23/21-1519.html"><strong>Minimax optimal approaches to the label shift problem</strong></a><br />
S Maity, Y Sun, M Banerjee. <em>Journal of Machine Learning Research</em> (2022).</p>

<p><a href="https://www.jmlr.org/papers/v23/21-0739.html"><strong>Meta-analysis of heterogeneous data: integrative sparse regression in high-dimensions</strong></a><br />
S Maity, Y Sun, M Banerjee. <em>Journal of Machine Learning Research</em> (2022).</p>

<p><a href="http://arxiv.org/abs/2012.01618"><strong>Matrix Completion Methods for the Total Electron Content Video Reconstruction</strong></a><br />
H Sun, Z Hua, J Ren, S Zou, Y Sun, Y Chen. <em>Annals of Applied Statistics</em> (2022+).</p>

<p><a href="https://epubs.siam.org/doi/abs/10.1137/19M1262760"><strong>Uniform bounds for invariant subspace perturbations</strong></a><br />
A Damle, Y Sun. <em>SIAM Journal of Matrix Analysis and Applications</em> (2020).<br /></p>

<p><a href="https://projecteuclid.org/euclid.ejs/1580202033"><strong>Statistical convergence of the EM algorithm on Gaussian mixture models</strong></a><br />
R Zhao, Y Li, Y Sun. <em>Electronic Journal of Statistics</em> (2020).</p>

<p><a href="https://doi.org/10.1038/s41596-018-0098-2"><strong>Creation and analysis of biochemical constraint-based models using the COBRA Toolbox v. 3.0</strong></a><br />
L Heirendt et al. <em>Nature Protocols</em> (2019).</p>

<p><a href="https://doi.org/10.1080/00401706.2016.1247017"><strong>A geometric approach to archetypal analysis and nonnegative matrix factorization</strong></a><br />
A Damle, Y Sun. <em>Technometrics</em> (2017).</p>

<p><a href="http://www.jmlr.org/papers/v18/16-002.html"><strong>Communication-efficient sparse regression</strong></a><br />
JD Lee, Q Liu, Y Sun, JE Taylor. <em>Journal of Machine Learning Research</em> (2017).</p>

<p><a href="https://projecteuclid.org/euclid.aos/1460381681"><strong>Exact post-selection inference, with application to the lasso</strong></a><br />
JD Lee, DL Sun, Y Sun, JE Taylor. <em>Annals of Statistics</em> (2016).</p>

<p><a href="https://doi.org/10.15252/msb.20156157"><strong>Do genome‐scale models need exact solvers or clearer standards?</strong></a><br />
A Ebrahim et al. <em>Molecular Systems Biology</em> (2015).</p>

<p><a href="https://www.pnas.org/content/112/34/10810.long"><strong>Systems biology definition of the core proteome of metabolism and expression is consistent with high-throughput data</strong></a><br />
L Yang et al. <em>Proceedings of the National Academy of Sciences</em> (2015).</p>

<p><a href="https://projecteuclid.org/euclid.ejs/1427990067"><strong>On model selection consistency of regularized M-estimators</strong></a><br />
JD Lee, Y Sun, JE Taylor. <em>Electronic Journal of Statistics</em> (2015).<br />
A conference version appeared at <em>NIPS 2013</em>.</p>

<p><a href="https://doi.org/10.1137/130921428"><strong>Proximal Newton-type methods for minimizing composite functions</strong></a><br />
JD Lee, Y Sun, MA Saunders. <em>SIAM Journal on Optimization</em> (2014).<br />
A conference version appeared at <em>NIPS 2012</em>.</p>

<p><a href="https://doi.org/10.1021/am402221u"><strong>Humidity effects on anisotropic nanofriction behaviors of aligned carbon nanotube carpets</strong></a><br />
J Zhang, H Lu, Y Sun, L Ci, PM Ajayan, J Lou. <em>ACS Applied Materials &amp; Interfaces</em> (2013).</p>

<p><a href="https://doi.org/10.1186/1471-2105-14-240"><strong>Robust flux balance analysis of multiscale biochemical reaction networks</strong></a><br />
Y Sun, RMT Fleming, I Thiele, MA Saunders. <em>BMC Bioinformatics</em> (2013).<br /></p>

<p><a href="https://doi.org/10.1021/la2010024"><strong>Nanostructure on taro leaves resists fouling by colloids and bacteria under submerged conditions</strong></a><br />
J Ma, Y Sun, K Gleichauf, J Lou, Q Li. <em>Langmuir</em> (2011).</p>

<p><a href="https://doi.org/10.1016/j.apsusc.2009.10.107"><strong>Regular and reverse nanoscale stick-slip behavior: Modeling and experiments</strong></a><br />
F Landolsi, Y Sun, H Lu, FH Ghorbel, J Lou. <em>Applied Surface Science</em> (2010).</p>

<p><a href="https://doi.org/10.1115/1.3223620"><strong>Nanoscale friction dynamic modeling</strong></a><br />
F Landolsi, FH Ghorbel, J Lou, H Lu, Y Sun. <em>ASME Journal of Dynamic Systems, Measurement &amp; Control</em> (2009).</p>

<p><a href="https://doi.org/10.1016/j.carbon.2008.05.010"><strong>Friction and adhesion properties of vertically aligned multi-walled carbon nanotube arrays and fluoro-nanodiamond films</strong></a><br />
H Lu, J Goldman, F Ding, Y Sun, MX Pulikkathara, VN Khabashesku, BI Yakobson, J Lou. <em>Carbon</em> (2008).</p>

<p><a href="https://doi.org/10.1063/1.2936866"><strong>Mesoscale reverse stick-slip nanofriction behavior of vertically aligned multiwalled carbon nanotube superlattices</strong></a><br />
J Lou, F Ding, H Lu, J Goldman, Y Sun, BI Yakobson. <em>Applied Physics Letters</em> (2008).</p>

<h3 id="conference-papers">Conference papers</h3>

<p><a href="https://openreview.net/forum?id=E8wDxddIqU"><strong>Distributionally robust performative prediction</strong></a><br />
S Xue, Y Sun. <em>NeurIPS 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=8wzYdXWYJv"><strong>Efficient multi-prompt evaluation of LLMs</strong></a><br />
F Maia Polo, R Xu, L Weber, M Silva, O Bhardwaj, L Choshen, A Oliveira, Y Sun, M Yurochkin. <em>NeurIPS 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=VOVyeOzZx0"><strong>Weak Supervision Performance Evaluation via Partial Identification</strong></a><br />
F Maia Polo, M Yurochkin, M Banerjee, S Maity, Y Sun. <em>NeurIPS 2024</em>.</p>

<p><a href="https://arxiv.org/abs/2403.04224"><strong>Aligners: Decoupling LLMs and Alignment</strong></a><br />
L Ngweta, M Agarwal, S Maity, A Gittens, Y Sun, M Yurochkin. <em>EMNLP Findings 2024</em>.<br />
A short version appeared as a <em>ICLR 2024 TinyPaper</em>.</p>

<p><a href="https://openreview.net/forum?id=YwrNePfb3E"><strong>Prompt Exploration with Prompt Regression</strong></a><br />
M Feffer, R Xu, Y Sun, M Yurochkin. <em>COLM 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=Zb0ajZ7vAt"><strong>Large Language Model Routing with Benchmark Datasets</strong></a><br />
T Shnitzer, A Ou, M Silva, K Soule, Y Sun, J Solomon, N Thompson, M Yurochkin. <em>COLM 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=qAml3FpfhG"><strong>tinyBenchmarks: evaluating LLMs with few examples</strong></a><br />
F Maia Polo, L Weber, L Choshen, Y Sun, G Xu, M Yurochkin. <em>ICML 2024</em>.</p>

<p><a href="https://dl.acm.org/doi/10.1145/3630106.3658929"><strong>Algorithmic Fairness in Performative Policy Learning: Escaping the  Impossibility of Group Fairness</strong></a><br />
S Somerstep, Y Ritov, Y Sun. <em>FAccT 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=vEfmVS5ywF"><strong>Learning in reverse causal strategic environments with ramifications on two-sided markets</strong></a><br />
S Somerstep, Y Sun, Y Ritov. <em>ICLR 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=PhMrGCMIRL"><strong>Fusing Models with Complementary Expertise</strong></a><br />
H Wang, F Maia Polo, Y Sun, S Kundu, E Xing, M Yurochkin. <em>ICLR 2024</em>.</p>

<p><a href="https://openreview.net/forum?id=q4SiDyYQbo"><strong>An Investigation of Representation and Allocation Harms in Contrastive Learning</strong></a><br />
S Maity, M Agarwal, M Yurochkin, Y Sun. <em>ICLR 2024</em>.<br /></p>

<p><a href="https://openreview.net/forum?id=Ifq8GMdqJK"><strong>Conditional independence testing under model misspecification</strong></a><br />
F Maia Polo, Y Sun, M Banerjee. <em>NeurIPS 2023</em></p>

<p><a href="https://proceedings.mlr.press/v202/ngweta23a.html"><strong>Simple Disentanglement of Style and Content in Visual Representations</strong></a><br />
L Ngweta, S Maity, A Gittens, Y Sun, M Yurochkin. <em>ICML 2023</em>.</p>

<p><a href="https://openreview.net/forum?id=DBMttEEoLbw"><strong>Understanding new tasks through the lens of training data via exponential tilting</strong></a><br />
S Maity, M Yurochkin, M Banerjee, Y Sun. <em>ICLR 2023</em>.</p>

<p><a href="https://openreview.net/forum?id=2SV2dlfBuE3"><strong>Predictor-corrector algorithms for stochastic optimization under gradual distribution shift</strong></a><br />
S Maity, D Mukherjee, M Banerjee, Y Sun. <em>ICLR 2023</em>.</p>

<p><a href="https://openreview.net/forum?id=0paCJSFW7j"><strong>ISAAC Newton: Input-based Approximate Curvature for Newton’s Method</strong></a><br />
F Petersen, T Sutter, C Borgelt, D Huh, H Kuehne, Y Sun, O Deussen. <em>ICLR 2023</em>.</p>

<p><a href="https://openreview.net/forum?id=oWqWiazEb62"><strong>Calibrated Data-Dependent Constraints with Exact Satisfaction Guarantees</strong></a><br />
S Xue, M Yurochkin, Y Sun. <em>NeurIPS 2022</em>.</p>

<p><a href="https://openreview.net/forum?id=XSNfXG9HBAu"><strong>Domain Adaptation meets Individual Fairness. And they get along.</strong></a><br />
D Mukherjee, F Petersen, M Yurochkin, Y Sun. <em>NeurIPS 2022</em>.</p>

<p><a href="https://openreview.net/forum?id=qGeqg4_hA2"><strong>Post-processing for Individual Fairness</strong></a><br />
F Petersen, D Mukherjee, Y Sun, M Yurochkin. <em>NeurIPS 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=Tv0O_cAdKtW"><strong>On sensitivity of meta-learning to support data</strong></a><br />
M Agarwal, M Yurochkin, Y Sun. <em>NeurIPS 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=6mUrD5rg-UU"><strong>Does enforcing fairness mitigate biases caused by subpopulation shift?</strong></a><br />
S Maity, D Mukherjee, M Yurochkin, Y Sun. <em>NeurIPS 2021</em>.</p>

<p><a href="https://proceedings.mlr.press/v139/mukherjee21a.html"><strong>Outlier-Robust Optimal Transport</strong></a><br />
D Mukherjee, A Guha, J Solomon, Y Sun, M Yurochkin. <em>ICML 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=z9k8BWL-_2u"><strong>Statistical Inference for Individual Fairness</strong></a><br />
S Maity, S Xue, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=71zCSP_HuBN"><strong>Individually Fair Rankings</strong></a><br />
A Bower, H Eftekhari, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=JBAa9we1AL"><strong>Individually fair gradient boosting</strong></a><br />
A Vargo, F Zhang, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><a href="https://openreview.net/forum?id=DktZb97_Fx"><strong>SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness</strong></a><br />
M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><a href="http://proceedings.mlr.press/v119/mukherjee20a.html"><strong>Two simple ways to learn individual fairness metrics from data</strong></a><br />
D Mukherjee, M Yurochkin, M Banerjee, Y Sun. <em>ICML 2020</em>.<br /></p>

<p><a href="http://proceedings.mlr.press/v108/xue20a.html"><strong>Auditing ML models for individual bias and unfairness</strong></a><br />
S Xue, M Yurochkin, Y Sun. <em>AISTATS 2020</em>.</p>

<p><a href="https://iclr.cc/virtual_2020/poster_BkluqlSFDS.html"><strong>Federated Learning with Matched Averaging</strong></a><br />
H Wang, M Yurochkin, Y Sun, D Papailiopoulos, Y Khazaeni. <em>ICLR 2020</em>.</p>

<p><a href="http://www.openreview.net/pdf?id=B1gdkxHFDH"><strong>Training individually fair machine learning models with Sensitive Subspace Robustness</strong></a><br />
M Yurochkin, A Bower, Y Sun. <em>ICLR 2020</em>.<br /></p>

<p><a href="http://proceedings.mlr.press/v97/yurochkin19b.html"><strong>Dirichlet Simplex Nest and Geometric Inference</strong></a><br />
M Yurochkin, A Guha, Y Sun, XL Nguyen. <em>ICML 2019</em>.<br /></p>

<p><a href="http://proceedings.mlr.press/v89/fan19a.html"><strong>Precision Matrix Estimation with Noisy and Missing Data</strong></a><br />
R Fan, B Jang, Y Sun, S Zhou. <em>AISTATS 2019</em>.</p>

<p><a href="https://www.fatml.org/media/documents/debiasing_representations.pdf"><strong>Debiasing representations by removing unwanted variation due to protected attributes</strong></a><br />
A Bower, L Niss, Y Sun, A Vargo. <em>FAT/ML 2018</em>.</p>

<p><a href="https://papers.nips.cc/paper/6187-feature-distributed-sparse-regression-a-screen-and-clean-approach"><strong>Feature-distributed sparse regression: a screen-and-clean approach</strong></a><br />
J Yang, MW Mahoney, M Saunders, Y Sun. <em>NIPS 2016</em>.</p>

<p><a href="https://papers.nips.cc/paper/5816-evaluating-the-statistical-significance-of-biclusters"><strong>Evaluating the statistical significance of biclusters</strong></a><br />
JD Lee, Y Sun, JE Taylor. <em>NIPS 2015</em>.</p>

<p><a href="http://proceedings.mlr.press/v32/sunb14.html"><strong>Learning Mixtures of Linear Classifiers</strong></a><br />
Y Sun, S Ioannidis, A Montanari. <em>ICML 2014</em>.</p>

<p><a href="https://proceedings.neurips.cc/paper/2013/hash/0266e33d3f546cb5436a10798e657d97-Abstract.html"><strong>On model selection consistency of regularized M-estimators</strong></a><br />
JD Lee, Y Sun, JE Taylor. <em>NIPS 2013</em>.<br />
A <a href="https://projecteuclid.org/euclid.ejs/1427990067">journal version</a> appeared in the <em>Electronic Journal of Statistics</em> in 2015.</p>

<p><a href="https://dl.acm.org/doi/10.5555/2999134.2999227"><strong>Proximal Newton-type methods for minimizing composite functions</strong></a><br />
JD Lee, Y Sun, MA Saunders. <em>NIPS 2012</em>.<br />
A <a href="https://doi.org/10.1137/130921428">journal version</a> appeared in the <em>SIAM Journal on Optimization</em> in 2014.</p>

<h3 id="book-chapters">Book chapters</h3>

<p><a href="https://link.springer.com/chapter/10.1007/978-3-030-96896-0_7"><strong>Communication Efficient Model Fusion</strong></a><br />
M Yurochkin, Y Sun.<br />
In <em>Federated Learning: A Comprehensive Overview of Methods and Applications</em>.  H Ludwig, N Baracaldo (eds). Springer (2022).</p>

<p><a href="https://link.springer.com/chapter/10.1007/978-3-030-96896-0_4"><strong>Personalization in Federated Learning</strong></a><br />
M Agarwal, M Yurochkin, Y Sun.<br />
In <em>Federated Learning: A Comprehensive Overview of Methods and Applications</em>. H Ludwig, N Baracaldo (eds). Springer (2022).</p>

<h3 id="technical-reports">Technical reports</h3>

<p><a href="https://arxiv.org/abs/2304.12551"><strong>On uniform consistency of spectral embeddings</strong></a><br />
R Zhao, S Xue, Y Sun.</p>

<p><a href="http://arxiv.org/abs/2206.03515"><strong>How does overparametrization affect performance on minority groups?</strong></a><br />
S Maity, S Roy, S Xue, M Yurochkin, Y Sun.</p>

<p><a href="https://arxiv.org/abs/2204.06664"><strong>Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms</strong></a><br />
L Niss, Y Sun, A Tewari.</p>

<p><a href="https://arxiv.org/abs/1708.08552"><strong>An inexact subsampled proximal Newton-type method for large-scale machine learning</strong></a><br />
X Liu, CJ Hsieh, JD Lee, Y Sun.</p>

<p><a href="https://arxiv.org/abs/1706.08519"><strong>On conditional parity as a notion of non-discrimination in machine learning</strong></a><br />
Y Ritov, Y Sun, R Zhao.</p>

<p><a href="https://arxiv.org/abs/1403.3457"><strong>Valid post-correction inference for censored regression problems</strong></a><br />
Y Sun, JE Taylor.</p>

<h2 id="talks">Talks</h2>

<p><iframe src="/talks/map.html" height="393.75" width="700" style="aspect-ratio:16/9;"></iframe></p>


      </section>

      <footer>
  <p><i class="bullet-icon fas fa-map-marker-alt fa-fw"></i>271 West Hall<br>
  1085 S University Ave<br>
  Ann Arbor, MI 48109</p>
  <p><i class="bullet-icon fas fa-envelope fa-fw"></i>yuekai<i class="fas fa-at fa-fw"></i>umich.edu</p>
  <p><small>Hosted on <a href="http://github.com">GitHub</a> | Powered by <a href="http://jekyllrb.com/">Jekyll</a></small></p>
</footer>

    </div>
    <script src="https://yuekai.github.io/assets/js/scale.fix.js"></script>
    
    
  </body>
</html>