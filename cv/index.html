<!DOCTYPE html>
<html lang="en-US">
  <head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Curriculum Vitae | Yuekai Sun</title>
<meta name="generator" content="Jekyll v4.0.1" />
<meta property="og:title" content="Curriculum Vitae" />
<meta name="author" content="Yuekai Sun" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Yuekai’s academic site" />
<meta property="og:description" content="Yuekai’s academic site" />
<link rel="canonical" href="http://yuekai.github.io/cv/" />
<meta property="og:url" content="http://yuekai.github.io/cv/" />
<meta property="og:site_name" content="Yuekai Sun" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Curriculum Vitae" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Yuekai Sun"},"description":"Yuekai’s academic site","headline":"Curriculum Vitae","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://yuekai.github.io/assets/img/Yuekai.jpg"},"name":"Yuekai Sun"},"url":"http://yuekai.github.io/cv/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/css/style.css">
  <!--[if lt IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
  <![endif]-->
  <script src="https://kit.fontawesome.com/ef661a1083.js" crossorigin="anonymous"></script>
  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon/favicon.ico">
  <link rel="apple-touch-icon-precomposed" href="/assets/favicon/apple-touch-icon.png">
  
</head>
  <body>
    <div id="container">

      <header>
  <h1><a href="http://yuekai.github.io/">Yuekai Sun</a></h1>

  
  <figure id="profile-pic"><img src="/assets/img/Yuekai.jpg" alt="profile pic"></figure>
  
  
  <nav>
    <ul><li>
        <a href="/research/">Research</a>
      </li><li>
        <a href="/papers/">Papers</a>
      </li><li>
        <a href="/teaching/">Teaching</a>
      </li></ul>
  </nav>
</header>

      <section>

      <h1 id="curriculum-vitae">Curriculum Vitae</h1>

<h2 id="education">Education</h2>

<dl>
  <dt>2010–2015</dt>
  <dd><strong>PhD Computational &amp; Mathematical Engineering</strong>, Stanford University <br />
Thesis: <a href="https://searchworks.stanford.edu/view/11061393">Regularization in high-dimensional statistics</a></dd>
  <dt>2006–2010</dt>
  <dd><strong>BA Computational and Applied Mathematics (CAAM)</strong>, Rice University</dd>
  <dt>2002–2006</dt>
  <dd><a href="https://sanmarin.nusd.org">San Marin High School</a></dd>
</dl>

<h2 id="academic-experience">Academic experience</h2>

<dl>
  <dt>2016–</dt>
  <dd><strong>Assistant Professor of Statistics</strong>, University of Michigan</dd>
  <dt>2015–2016</dt>
  <dd><strong>Neyman Visiting Assistant Professor</strong>, UC Berkeley</dd>
  <dt>2013</dt>
  <dd><strong>Research Intern</strong>, Technicolor Research &amp; Innovation</dd>
  <dt>2008–2009</dt>
  <dd><strong>Teaching Fellow</strong>, <a href="https://breakthroughhouston.org/">Breakthrough Houston</a></dd>
</dl>

<h2 id="honors-and-awards">Honors and awards</h2>

<dl>
  <dt>2017</dt>
  <dd><strong><a href="https://www.tandfonline.com/doi/full/10.1080/00401706.2018.1562089">ASQ Jack Youden Prize</a></strong></dd>
  <dt>2010</dt>
  <dd><strong>Stanford School of Engineering Graduate Fellowship</strong></dd>
  <dt>2009</dt>
  <dd><strong><a href="https://caamweb.rice.edu/academics/undergraduate-programs/undergraduate-awards">Rice CAAM Chevron Prize</a></strong></dd>
</dl>

<h2 id="grants">Grants</h2>

<dl>
  <dt>Aug 2022–<br />Jul 2024</dt>
  <dd><strong>Confident Learning with Uncertainty Estimates</strong><br />
DARPA HR00112290111. PI: Elizabeth Hou. Subcontract amount: $200k.</dd>
  <dt>Aug 2021–<br />Jul 2024</dt>
  <dd><strong><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2113373">A Transfer Learning Approach to Algorithmic Fairness</a></strong><br />
NSF DMS-2113373. Co-PI: Mouli Banerjee. Award amount: $150k.</dd>
  <dt>Sep 2021–<br />Aug 2024</dt>
  <dd><strong><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2027737">ATD: Algorithmic Threat Detection and Mitigation with Robust Machine Learning</a></strong><br />
NSF DMS-2027737. Co-PI: Mouli Banerjee. Award amount: $330k.</dd>
  <dt>Sep 2019–<br />Aug 2022</dt>
  <dd><strong><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1916271">Integrative Analysis of Heterogeneous Datasets with High-Dimensional and Non-Standard Models</a></strong><br />
NSF DMS-1916271. Co-PI: Mouli Banerjee. Award amount: $180k.</dd>
  <dt>Aug 2018–<br />Jul 2021</dt>
  <dd><strong><a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1830247">ATD: Collaborative Research: Statistically Principled Real-Time Detection of Anomalies in Temporal Network Data</a></strong><br />
NSF DMS-1830247. Award amount: $75k.</dd>
</dl>

<h2 id="professional-activities">Professional activities</h2>

<dl>
  <dt>2023–</dt>
  <dd><strong>Co-editor</strong> (with Samory Kpotufe and Richard Samworth), Statistical Science Special Issue on “Learning Across Distributions”</dd>
  <dt>2023</dt>
  <dd><strong>Website committee chair</strong>, 2023 ICSA Applied Statistics Symposium</dd>
  <dt>2022–</dt>
  <dd><strong>Associate Editor</strong>, Statistical Science</dd>
</dl>

<h2 id="teaching">Teaching</h2>

<h3 id="university-of-michigan">University of Michigan</h3>

<dl>
  <dt>Win 2020-2023</dt>
  <dd><strong><a href="http://www-personal.umich.edu/~yuekai/stats606/">STATS 606: Computation and Optimization Methods in Statistics</a></strong><br />
This course combines STATS 608a and STATS 607b.</dd>
  <dt>Sum, Fall 2018, Fall 2022</dt>
  <dd><strong><a href="http://www-personal.umich.edu/~yuekai/stats415/">STATS 415: Data Mining and Machine Learning</a></strong><br /></dd>
  <dt>Win 2022</dt>
  <dd><strong>STATS 701: Topics in algorithmic fairness</strong></dd>
  <dt>Fall 2021, ‘17, ‘16, Win ‘17</dt>
  <dd><strong><a href="http://www-personal.umich.edu/~yuekai/stats413/">STATS 413: Applied Regression Analysis</a></strong></dd>
  <dt>Fall 2020</dt>
  <dd><strong>STATS 451: Bayesian Data Analysis</strong></dd>
  <dt>Fall 2018, ‘17</dt>
  <dd><strong>STATS 608a: Optimization Methods in Statistics</strong></dd>
  <dt>Sum 2018</dt>
  <dd><strong>VE 488: Data Mining and Machine Learning</strong><br />
This course was offered at the UM-SJTU Joint Institute; it is identical to STATS 415.</dd>
  <dt>Win 2019, ‘18</dt>
  <dd><strong>STATS 607b: Numerical Methods in Statistics</strong></dd>
</dl>

<h3 id="uc-berkeley">UC Berkeley</h3>

<dl>
  <dt>Spr 2016</dt>
  <dd><strong>STAT 153: Introduction to Time Series</strong></dd>
  <dt>Fall 2015</dt>
  <dd><strong>STAT 201B: Introduction to Statistics at an Advanced Level</strong></dd>
</dl>

<h2 id="phd-students">PhD students</h2>

<p><strong>Seamus Somerstep</strong> (co-advised with Ya’acov Ritov)<br />
PhD student, University of Michigan</p>

<p><strong>Daniele Bracale</strong> (co-advised with Mouli Banerjee)<br />
PhD student, University of Michigan</p>

<p><strong><a href="https://felipemaiapolo.github.io">Felipe Maia Polo</a></strong> (co-advised with Mouli Banerjee)<br />
PhD student, University of Michigan</p>

<p><strong>Pramit Das</strong> (co-advised with Mouli Banerjee)<br />
PhD student, University of Michigan</p>

<p><strong><a href="http://www-personal.umich.edu/~sxue/">Songkai Xue</a></strong><br />
PhD candidate, University of Michigan<br />
Songkai was an MS student from 2018–2020.</p>

<p><strong><a href="http://www-personal.umich.edu/~smaity/">Subha Maity</a></strong> (co-advised with Mouli Banerjee)<br />
PhD candidate, University of Michigan</p>

<p><strong><a href="https://lauraniss.com">Laura Niss</a></strong> (mainly advised by <a href="https://ambujtewari.github.io">Ambuj Tewari</a>) <br />
PhD Statistics, University of Michigan, 2022<br />
Thesis: <a href="https://hdl.handle.net/2027.42/174300">Topics in Sequential Decision Making and Algorithmic Fairness</a></p>

<p><strong>Roger Fan</strong> (mainly advised by <a href="https://sites.google.com/view/shuhengz">Shuheng Zhou</a>) <br />
PhD Statistics, University of Michigan, 2020<br />
Thesis: <a href="https://hdl.handle.net/2027.42/163035">Covariance Estimation with Missing and Dependent Data</a></p>

<p><strong>Ruofei Zhao</strong> <br />
PhD Statistics, University of Michigan, 2019 <br />
Thesis: <a href="https://hdl.handle.net/2027.42/151538">Convergence and Consistency Results in Spectral Clustering and Gaussian Mixture Models</a></p>

<h2 id="publications">Publications</h2>

<h3 id="journal-papers">Journal papers</h3>

<p><strong><a href="https://arxiv.org/abs/2111.10841">A linear adjustment based approach to posterior drift in transfer learning</a></strong><br />
S Maity, D Dutta, J Terhorst, Y Sun, M Banerjee. <em>Biometrika</em> (2023+).</p>

<p><strong><a href="https://jmlr.org/papers/v23/21-1519.html">Minimax optimal approaches to the label shift problem</a></strong><br />
S Maity, Y Sun, M Banerjee. <em>Journal of Machine Learning Research</em> (2022).</p>

<p><strong><a href="https://www.jmlr.org/papers/v23/21-0739.html">Meta-analysis of heterogeneous data: integrative sparse regression in high-dimensions</a></strong><br />
S Maity, Y Sun, M Banerjee. <em>Journal of Machine Learning Research</em> (2022).</p>

<p><strong><a href="http://arxiv.org/abs/2012.01618">Matrix Completion Methods for the Total Electron Content Video Reconstruction</a></strong><br />
H Sun, Z Hua, J Ren, S Zou, Y Sun, Y Chen. <em>Annals of Applied Statistics</em> (2022+).</p>

<p><strong><a href="https://epubs.siam.org/doi/abs/10.1137/19M1262760">Uniform bounds for invariant subspace perturbations</a></strong><br />
A Damle, Y Sun. <em>SIAM Journal of Matrix Analysis and Applications</em> (2020).<br /></p>

<p><strong><a href="https://projecteuclid.org/euclid.ejs/1580202033">Statistical convergence of the EM algorithm on Gaussian mixture models</a></strong><br />
R Zhao, Y Li, Y Sun. <em>Electronic Journal of Statistics</em> (2020).</p>

<p><strong><a href="https://doi.org/10.1080/00401706.2016.1247017">A geometric approach to archetypal analysis and nonnegative matrix factorization</a></strong><br />
A Damle, Y Sun. <em>Technometrics</em> (2017).<br />
<i class="fas fa-medal fa-fw"></i>2017 Technometrics Prize</p>

<p><strong><a href="http://www.jmlr.org/papers/v18/16-002.html">Communication-efficient sparse regression</a></strong><br />
JD Lee, Q Liu, Y Sun, JE Taylor. <em>Journal of Machine Learning Research</em> (2017).</p>

<p><strong><a href="https://projecteuclid.org/euclid.aos/1460381681">Exact post-selection inference with the lasso</a></strong><br />
JD Lee, DL Sun, Y Sun, JE Taylor. <em>Annals of Statistics</em> (2016).</p>

<p><strong><a href="https://www.pnas.org/content/112/34/10810.long">Systems biology definition of the core proteome of metabolism and expression is consistent with high-throughput data</a></strong><br />
L Yang, J Tan, EJ O’Brien, … Y Sun, MA Saunders, BO Palsson. <em>Proceedings of the National Academy of Sciences</em> (2015).</p>

<p><strong><a href="https://projecteuclid.org/euclid.ejs/1427990067">On model selection consistency of regularized M-estimators</a></strong><br />
JD Lee, Y Sun, JE Taylor. <em>Electronic Journal of Statistics</em> (2015).<br />
A conference version appeared at <em>NIPS 2013</em>.</p>

<p><strong><a href="https://doi.org/10.1137/130921428">Proximal Newton-type methods for minimizing composite functions</a></strong><br />
JD Lee, Y Sun, MA Saunders. <em>SIAM Journal on Optimization</em> (2014).<br />
A conference version appeared at <em>NIPS 2012</em>.</p>

<p><strong><a href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-240">Robust flux balance analysis of multiscale biochemical reaction networks</a></strong><br />
Y Sun, RMT Fleming, I Thiele, MA Saunders. <em>BMC Bioinformatics</em> (2013).<br /></p>

<h3 id="conference-papers">Conference papers</h3>

<p><strong><a href="https://openreview.net/forum?id=DBMttEEoLbw">Understanding new tasks through the lens of training data via exponential tilting</a></strong><br />
S Maity, M Yurochkin, M Banerjee, Y Sun. <em>ICLR 2023</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=2SV2dlfBuE3">Predictor-corrector algorithms for stochastic optimization under gradual distribution shift</a></strong><br />
S Maity, D Mukherjee, M Banerjee, Y Sun. <em>ICLR 2023</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=0paCJSFW7j">ISAAC Newton: Input-based Approximate Curvature for Newton’s Method</a></strong><br />
F Petersen, T Sutter, C Borgelt, D Huh, H Kuehne, Y Sun, O Deussen. <em>ICLR 2023</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=oWqWiazEb62">Calibrated Data-Dependent Constraints with Exact Satisfaction Guarantees</a></strong><br />
S Xue, M Yurochkin, Y Sun. <em>NeurIPS 2022</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=XSNfXG9HBAu">Domain Adaptation meets Individual Fairness. And they get along.</a></strong><br />
D Mukherjee, F Petersen, M Yurochkin, Y Sun. <em>NeurIPS 2022</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=qGeqg4_hA2">Post-processing for Individual Fairness</a></strong><br />
F Petersen, D Mukherjee, Y Sun, M Yurochkin. <em>NeurIPS 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=Tv0O_cAdKtW">On sensitivity of meta-learning to support data</a></strong><br />
M Agarwal, M Yurochkin, Y Sun. <em>NeurIPS 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=6mUrD5rg-UU">Does enforcing fairness mitigate biases caused by subpopulation shift</a></strong><br />
S Maity, D Mukherjee, M Yurochkin, Y Sun. <em>NeurIPS 2021</em>.</p>

<p><strong><a href="https://proceedings.mlr.press/v139/mukherjee21a.html">Outlier-Robust Optimal Transport</a></strong><br />
D Mukherjee, A Guha, J Solomon, Y Sun, M Yurochkin. <em>ICML 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=z9k8BWL-_2u">Statistical Inference for Individual Fairness</a></strong><br />
S Maity, S Xue, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=71zCSP_HuBN">Individually Fair Rankings</a></strong><br />
A Bower, H Eftekhari, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=JBAa9we1AL">Individually fair gradient boosting</a></strong><br />
A Vargo, F Zhang, M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><strong><a href="https://openreview.net/forum?id=DktZb97_Fx">SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness</a></strong><br />
M Yurochkin, Y Sun. <em>ICLR 2021</em>.</p>

<p><strong><a href="http://proceedings.mlr.press/v119/mukherjee20a.html">Two simple ways to learn individual fairness metrics from data</a></strong><br />
D Mukherjee, M Yurochkin, M Banerjee, Y Sun. <em>ICML 2020</em>.<br /></p>

<p><strong><a href="http://proceedings.mlr.press/v108/xue20a.html">Auditing ML models for individual bias and unfairness</a></strong><br />
S Xue, M Yurochkin, Y Sun. <em>AISTATS 2020</em>.</p>

<p><strong><a href="https://iclr.cc/virtual_2020/poster_BkluqlSFDS.html">Federated Learning with Matched Averaging</a></strong><br />
H Wang, M Yurochkin, Y Sun, D Papailiopoulos, Y Khazaeni. <em>ICLR 2020</em>.</p>

<p><strong><a href="http://www.openreview.net/pdf?id=B1gdkxHFDH">Training individually fair machine learning models with Sensitive Subspace Robustness</a></strong><br />
M Yurochkin, A Bower, Y Sun. <em>ICLR 2020</em>.<br /></p>

<p><strong><a href="http://proceedings.mlr.press/v97/yurochkin19b.html">Dirichlet Simplex Nest and Geometric Inference</a></strong><br />
M Yurochkin, A Guha, Y Sun, XL Nguyen. <em>ICML 2019</em>.<br /></p>

<p><strong><a href="http://proceedings.mlr.press/v89/fan19a.html">Precision Matrix Estimation with Noisy and Missing Data</a></strong><br />
R Fan, B Jang, Y Sun, S Zhou. <em>AISTATS 2019</em>.</p>

<p><strong><a href="https://www.fatml.org/media/documents/debiasing_representations.pdf">Debiasing representations by removing unwanted variation due to protected attributes</a></strong><br />
A Bower, L Niss, Y Sun, A Vargo. <em>FAT/ML 2018</em>.<br /></p>

<p><strong><a href="https://papers.nips.cc/paper/6187-feature-distributed-sparse-regression-a-screen-and-clean-approach">Feature-distributed sparse regression: a screen-and-clean approach</a></strong><br />
J Yang, MW Mahoney, M Saunders, Y Sun. <em>NIPS 2016</em>.</p>

<p><strong><a href="https://papers.nips.cc/paper/5816-evaluating-the-statistical-significance-of-biclusters">Evaluating the statistical significance of biclusters</a></strong><br />
JD Lee, Y Sun, JE Taylor. <em>NIPS 2015</em>.</p>

<p><strong><a href="http://proceedings.mlr.press/v32/sunb14.html">Learning Mixtures of Linear Classifiers</a></strong><br />
Y Sun, S Ioannidis, A Montanari. <em>ICML 2014</em>.</p>

<p><strong><a href="https://projecteuclid.org/euclid.ejs/1427990067">On model selection consistency of regularized M-estimators</a></strong><br />
JD Lee, Y Sun, JE Taylor. <em>NIPS 2013</em>.<br />
A journal version appeared in the <em>Electronic Journal of Statistics</em> in 2015.</p>

<p><strong><a href="https://doi.org/10.1137/130921428">Proximal Newton-type methods for minimizing composite functions</a></strong><br />
JD Lee, Y Sun, MA Saunders. <em>NIPS 2012</em>.<br />
A journal version appeared in the <em>SIAM Journal on Optimization</em> in 2014.</p>

<h3 id="book-chapters">Book chapters</h3>

<p><strong><a href="https://link.springer.com/chapter/10.1007/978-3-030-96896-0_7">Communication Efficient Model Fusion</a></strong><br />
M Yurochkin, Y Sun.<br />
In <em>Federated Learning: A Comprehensive Overview of Methods and Applications</em>.  H Ludwig, N Baracaldo (eds). Springer (2022).</p>

<p><strong><a href="https://link.springer.com/chapter/10.1007/978-3-030-96896-0_4">Personalization in Federated Learning</a></strong><br />
M Agarwal, M Yurochkin, Y Sun.<br />
In <em>Federated Learning: A Comprehensive Overview of Methods and Applications</em>. H Ludwig, N Baracaldo (eds). Springer (2022).</p>

<h3 id="technical-reports">Technical reports</h3>

<p><strong><a href="https://arxiv.org/abs/2204.06664">Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms</a></strong><br />
L Niss, Y Sun, A Tewari.</p>

<p><strong><a href="https://arxiv.org/abs/1708.08552">An inexact subsampled proximal Newton-type method for large-scale machine learning</a></strong><br />
X Liu, CJ Hsieh, JD Lee, Y Sun.</p>

<p><strong><a href="https://arxiv.org/abs/1706.08519">On conditional parity as a notion of non-discrimination in machine learning</a></strong><br />
Y Ritov, Y Sun, R Zhao.</p>

<p><strong><a href="https://arxiv.org/abs/1403.3457">Valid post-correction inference for censored regression problems</a></strong><br />
Y Sun, JE Taylor.</p>

<h2 id="talks">Talks</h2>

<p><iframe src="/talks/map.html" height="393.75" width="700" style="aspect-ratio: 16/9; border: none; border-radius: 8px;"></iframe></p>


      </section>

      <footer>
  <p><i class="bullet-icon fas fa-map-marker-alt fa-fw"></i>271 West Hall<br>
  1085 S University Ave<br>
  Ann Arbor, MI 48109</p>

  <p><i class="bullet-icon fas fa-envelope fa-fw"></i>yuekai<i class="fas fa-at fa-fw"></i>umich.edu</p>

  <p class="small">Hosted on GitHub | Powered by <a href="https://jekyllrb.com/">Jekyll</a></p>
</footer>

    </div>
    <script src="/assets/js/scale.fix.js"></script>
    
  </body>
</html>